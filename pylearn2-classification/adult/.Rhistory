SessionInfo()
?t.test
require(graphics)
t.test(1:10, y = c(7:20))      # P = .00001855
t.test(1:10, y = c(7:20, 200)) # P = .1245    -- NOT significant anymore
## Classical example: Student's sleep data
plot(extra ~ group, data = sleep)
## Traditional interface
with(sleep, t.test(extra[group == 1], extra[group == 2]))
## Formula interface
t.test(extra ~ group, data = sleep)
sleep
rm(list=ls(0))
rm(list=ls())
sleep
library(graphics)
citation(ade)
citation('ade')
citation('ade4')
library(ade4)
library(ape)
?consensus
print(5)
Sys.getenv
?prod
prod(8)
prod(1:8)
prod(1:3)
?prod
?dt
dt(2,5)
dnorm(0,1,100)
dt(10,5,10)
source('~/PycharmProjects/DeepLearningTutorials/dpdata/multiple_deeplearning.R')
preprocessing(mode='Prediciton',training_data='train.csv',entending_data='extend.csv')
preprocessing(mode='Prediciton',training_data='train.csv',extending_data='extend.csv')
preprocessing(mode='Prediciton',training_data='train.csv',extending_data='extend.csv')
preprocessing(mode='Predicton',training_data='train.csv',extending_data='extend.csv')
preprocessing(mode='Predicton',training_data='train.csv',extending_data='extend.csv')
preprocessing(mode='Predicton',training_data='train.csv',extending_data='extend.csv')
source('~/.active-rstudio-document')
source('~/PycharmProjects/DeepLearningTutorials/dpdata/multiple_deeplearning.R')
preprocessing(mode='Predicton',training_data='train.csv',extending_data='extend.csv')
debugSource('~/PycharmProjects/DeepLearningTutorials/dpdata/multiple_deeplearning.R')
preprocessing(mode='Predicton',training_data='train.csv',extending_data='extend.csv')
mode
debugSource('~/PycharmProjects/DeepLearningTutorials/dpdata/multiple_deeplearning.R')
install.packages('survival')
library(survival)
resp <- levels(logan$occupation)
n <- nrow(logan)
indx <- rep(1:n, length(resp))
logan2 <- data.frame(logan[indx,],
id = indx,
tocc = factor(rep(resp, each=n)))
logan2$case <- (logan2$occupation == logan2$tocc)
clogit(case ~ tocc + tocc:education + strata(id), logan2)
logan2
head(logan2)
case
logan2$case
summary(logan2)
resp
indx
install.packages('ForeCA')
library(ForeCA)
a=rnorm(100,0,1)
a=rnorm(1000,0,1)
a=matrix(a,10,100)
a
head(a)
a=matrix(rnorm(1000),100,10)
a
cor(sclae(a))
cor(scale(a))
cov(scale(a))
apply(a,2,var)
apply(a,1,var)
apply(a,2,mean)
b=scale(a)
apply(    b,2,mean)
apply(b,2,mean)
apply(b,2,var)
cor(b)
whiten(b)$U
c=whiten(b)$U
apply(c,2,var)
apply(c,2,mean)
apply(a,2,mean)
apply(a,2,var)
d=whiten(a)$U
apply(d,2,var)
apply(d,2,mean)
a=matrix(rnorm(1000,100,10),100,10)
a
head(a)
b=scalce(a)
b=scale(a)
summary()
summary(b)
apply(a,2,mean,var)
apply(a,2,mean)
apply(a,2,var)
a=matrix(rnorm(1000,100,10),100,10)
apply(a,2,var)
var(a[,1])
std(a[,1])
a=matrix(rnorm(1000,100,10),100,10)
b=scale(a)
c=whiten(a)$U
d=whiten(b)$U
apply(c,2,man)
apply(c,2,mean)
apply(c,2,var)
apply(b,2,mean)
apply(b,2,var)
apply(d,2,var)
cov(c)
cov(D)
cov(d)
d
d
c
head(c)
head(d)
zeroone_normalizaiton=function(x){
x=scale(x,scale=F)
#y=whiten(features)$U
y=(x-min(x))/(max(x)-min(x))
return(y)
}
a=rnorm(100,10,1)
a
zeroone_normalizaiton(a)
a
b=zeroone_normalizaiton(a)
b
zeroone_normalizaiton=function(x){
#x=scale(x,scale=F)
#y=whiten(features)$U
y=(x-min(x))/(max(x)-min(x))
return(y)
}
c=zeroone_normalizaiton(a)
c
b
b-c
mean(zeroone_normalizaiton(rnorm(1000,100,10)))
mean(zeroone_normalizaiton(rnorm(1000,1,1)))
mean(b)
mean(c)
lcg_extend <- read.csv("~/PycharmProjects/DeepLearningTutorials/dpdata/lcg_extend.csv")
View(lcg_extend)
a=lcg_extend
a=a[,1:19]
head(a)
a=a[,1:18]
head(a)
a=a[,1:17]
cor(a)
zeroone_normalizaiton=function(x){
x=scale(x)
#y=whiten(features)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
b=zeroone_normalizaiton(a)
summary(b)
zeroone_normalizaiton=function(x){
x=scale(x,scale=F)
#y=whiten(features)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
zeroone_normalizaiton=function(x){
x=scale(x,scale=F)
#y=whiten(features)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
b=zeroone_normalizaiton(a)
summary(b)
sapply(a,zeroone_normalizaiton)
b=sapply(a,zeroone_normalizaiton)
summary(b)
zeroone_normalizaiton=function(x){
x=scale(x)
#y=whiten(features)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
b=sapply(a,zeroone_normalizaiton)
summary(b)
zeroone_normalizaiton=function(x){
x=scale(x)
y=whiten(features)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
b=sapply(a,zeroone_normalizaiton)
library(ForeCA)
b=sapply(a,zeroone_normalizaiton)
zeroone_normalizaiton=function(x){
x=scale(x)
x=whiten(x)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
b=sapply(a,zeroone_normalizaiton)
summary(b)
zeroone_normalizaiton=function(x){
#x=scale(x)
#x=whiten(x)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
x=scale(a,scale=F)
y=whiten(x)$U
b=sapply(y,zeroone_normalizaiton)
summary(b)
y
summary(y)
zeroone_normalizaiton=function(x){
#x=scale(x)
#x=whiten(x)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
b=sapply(y,zeroone_normalizaiton)
b
b=sapply(y[,1],zeroone_normalizaiton)
b
y[,1]
summary(y[,1])
x=y[,1]
y=(x-min(x))/(max(x)-min(x))
y
zeroone_normalizaiton=function(x){
x=scale(x)
#x=whiten(x)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
head(a)
sapply(a,zeroone_normalizaiton)
summary(sapply(a,zeroone_normalizaiton))
zeroone_normalizaiton=function(x){
x=scale(x)
#x=whiten(x)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
a=matrix(rnorm(1000,10,2),100,10)
a
b=scale(a)
summary(a)
apply(a,2,var)
apply(b,2,var)
c=sapply(a,zeroone_normalizaiton)
apply(c,2,var)
c
c=apply(a,2,zeroone_normalizaiton)
c
apply(c,2,var)
apply(b,2,var)
zeroone_normalizaiton=function(x){
#x=scale(x)
#x=whiten(x)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
c=apply(b,2,zeroone_normalizaiton)
apply(c,2,var)
apply(b,2,var)
c[,1]
b[,1]
zeroone_normalizaiton=function(x){
x=scale(x,scale=F)
#x=whiten(x)$U #做白化之前一定要先减去均值，对于图像要白化
y=(x-min(x))/(max(x)-min(x)) # 0-1 归一化做不做scale都没有关系
return(y)
}
a=rnorm(100,10,3)
a
zeroone_normalizaiton(a)
q=zeroone_normalizaiton(a)
var(a)
var(q)
b=scale(a)
var(b)
b
max(b)
max(abs(b))
b=b/max(abs(b))
b
var(b)
install.packages('mclogit')
library(mclogit)
??mclogit
data(Transport)
summary(mclogit(
cbind(resp,suburb)~distance+cost,
data=Transport
))
cbind(resp,suburb)
cbind(resp,suburb)
attach(Transport)
cbind(resp,suburb)
data(electors)
cbind(Freq,interaction(time,class))
attach(electors)
cbind(Freq,interaction(time,class))
library(survival)
resp <- levels(logan$occupation)
n <- nrow(logan)
indx <- rep(1:n, length(resp))
logan2 <- data.frame(logan[indx,],
id = indx,
tocc = factor(rep(resp, each=n)))
logan2$case <- (logan2$occupation == logan2$tocc)
clogit(case ~ tocc + tocc:education + strata(id), logan2)
install.packages('survival')
library(survival)
?clogit
resp <- levels(logan$occupation)
resp
n <- nrow(logan)
n
indx <- rep(1:n, length(resp))
indx
logan2 <- data.frame(logan[indx,],
id = indx,
tocc = factor(rep(resp, each=n)))
logan2$case <- (logan2$occupation == logan2$tocc)
logan2$case
logan2$tocc
unique(logan2$tocc)
strata(id)
?strata()
logan2$id
unique(logan2$id)
logan2
View(logan2)
clogit(case ~ tocc + tocc:education + strata(id), logan2)
View(logan2)
unique(logan2$id)
library(mclogit)
?mclogit
data(Transport)
summary(mclogit(
cbind(resp,suburb)~distance+cost,
data=Transport
))
install.packages(Epi)
install.packages('Epi')
library(Epi)
?clogistic
data(bdendo)
clogistic(d ~ cest + dur, strata=set, data=bdendo)
View(bdendo)
data(bdendo)
summary(clogistic(d ~ cest + dur, strata=set, data=bdendo))
data(bdendo)
q=clogistic(d ~ cest + dur, strata=set, data=bdendo)
q.predict
confint(q)
predict(q)
?clogit
resp <- levels(logan$occupation)
n <- nrow(logan)
indx <- rep(1:n, length(resp))
logan2 <- data.frame(logan[indx,],
id = indx,
tocc = factor(rep(resp, each=n)))
logan2$case <- (logan2$occupation == logan2$tocc)
clogit(case ~ tocc + tocc:education + strata(id), logan2)
q=clogit(case ~ tocc + tocc:education + strata(id), logan2)
predict(q)
View(logan2)
summary(q)
fitted(q)
predict(q,data.frame(logan2$tocc))
predict(q)
p=predict(q)
?predict
clogit(case ~ tocc + tocc:education + strata(id), logan2)
clogit(case ~ tocc + tocc:education + strata(id), logan2)
?predict.coxph
clogit.predict
?clogit
clogit(case ~ tocc + tocc:education + strata(id), logan2)
f=clogit(case ~ tocc + tocc:education + strata(id), logan2)
predict(f,newdata=data.frame(logan2$tocc))
predict(f,newdata=data.frame(a=logan2$tocc))
factor(rep(c("M", "F"), c(6, 6)))
ldose <- rep(0:5, 2)
numdead <- c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16)
sex <- factor(rep(c("M", "F"), c(6, 6)))
SF <- cbind(numdead, numalive = 20-numdead)
budworm.lg <- glm(SF ~ sex*ldose, family = binomial)
summary(budworm.lg)
predict(f,newdata=data.frame(tocc=logan2$tocc))
predict(f,newdata=data.frame(tocc=logan2$tocc,education=logan2$education,id=logan2$id))
f=clogit(case ~ tocc + tocc*education + strata(id), logan2)
f
f=clogit(case ~ tocc + tocc:education + strata(id), logan2)
f
summary(predict(f,newdata=data.frame(tocc=logan2$tocc,education=logan2$education,id=logan2$id)))
summary(f)
scale((20,40,60,80))
scale(c(20,40,60,80))
scale(c(20,40,60,80,1,3,5,7))
setwd("~/PycharmProjects/pylearn2Tutorial/pylearn2-classification/adult")
a=read.csv('test_v_R',header=T)
a=read.csv('test_v_R.csv',header=T)
b=read.csv('test_R.csv',header=T)
c=read.csv('train_v_R.csv',header=T)
summary(a)
summary(b)
summary(c)
